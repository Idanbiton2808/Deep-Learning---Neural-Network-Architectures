# Deep-Learning---Neural-Network-Architectures
In this project, i will demonstrate the training of different Convolutional Neural Networks (CNNs) on the MNIST dataset using PyTorch.

Data Loading and Preprocessing:
-Efficiently loading and transforming the MNIST dataset using PyTorch's DataLoader and ToTensor.

Model Architectures: Implementing and comparing different CNN architectures, including:

-A basic CNN with two convolutional layers, dropout, and fully connected layers.

-A three-layer CNN with additional convolutional layers and fully connected layers.

-Another variant of a three-layer CNN with max pooling.

Training Process: 
-Step-by-step guide to training the models, including loss calculation, backpropagation, and optimization using Adam optimizer.
Evaluation:
-Testing the models and evaluating their performance using accuracy and loss metrics.

Hyperparameter Tuning:
-Conducting experiments to find the best learning rate, batch size, and number of epochs for optimal model performance.
